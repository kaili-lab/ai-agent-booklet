import 'dotenv/config';
import { ChatOpenAI } from '@langchain/openai';
import { z } from 'zod';

const model = new ChatOpenAI({
    modelName: process.env.MODEL_NAME,
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
    configuration: {
        baseURL: process.env.OPENAI_BASE_URL,
    },
});

// ä½¿ç”¨ zod å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ ¼å¼
const schema = z.object({
    name: z.string().describe("å§“å"),
    birth_year: z.number().describe("å‡ºç”Ÿå¹´ä»½"),
    death_year: z.number().describe("å»ä¸–å¹´ä»½"),
    nationality: z.string().describe("å›½ç±"),
    occupation: z.string().describe("èŒä¸š"),
    famous_works: z.array(z.string()).describe("è‘—åä½œå“åˆ—è¡¨"),
    biography: z.string().describe("ç®€çŸ­ä¼ è®°")
});

const structuredModel = model.withStructuredOutput(schema);

const prompt = `è¯¦ç»†ä»‹ç»è«æ‰ç‰¹çš„ä¿¡æ¯ã€‚`;

console.log("ğŸŒŠ æµå¼ç»“æ„åŒ–è¾“å‡ºæ¼”ç¤ºï¼ˆwithStructuredOutputï¼‰\n");

try {
    const stream = await structuredModel.stream(prompt);

    let chunkCount = 0;
    let result = null;

    console.log("ğŸ“¡ æ¥æ”¶æµå¼æ•°æ®:\n");

    for await (const chunk of stream) {
        chunkCount++;
        result = chunk;

        console.log(`[Chunk ${chunkCount}]`);
        console.log(JSON.stringify(chunk, null, 2));
    }

    console.log(`\nâœ… å…±æ¥æ”¶ ${chunkCount} ä¸ªæ•°æ®å—\n`);

    if (result) {
        console.log("ğŸ“Š æœ€ç»ˆç»“æ„åŒ–ç»“æœ:\n");
        console.log(JSON.stringify(result, null, 2));

        console.log("\nğŸ“ æ ¼å¼åŒ–è¾“å‡º:");
        console.log(`å§“å: ${result.name}`);
        console.log(`å‡ºç”Ÿå¹´ä»½: ${result.birth_year}`);
        console.log(`å»ä¸–å¹´ä»½: ${result.death_year}`);
        console.log(`å›½ç±: ${result.nationality}`);
        console.log(`èŒä¸š: ${result.occupation}`);
        console.log(`è‘—åä½œå“: ${result.famous_works.join(', ')}`);
        console.log(`ä¼ è®°: ${result.biography}`);
    }

} catch (error) {
    console.error("\nâŒ é”™è¯¯:", error.message);
}
