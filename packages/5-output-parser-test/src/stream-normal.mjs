import 'dotenv/config';
import { ChatOpenAI } from '@langchain/openai';

const model = new ChatOpenAI({
    modelName: process.env.MODEL_NAME,
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
    configuration: {
        baseURL: process.env.OPENAI_BASE_URL,
    },
});

const prompt = `è¯¦ç»†ä»‹ç»è«æ‰ç‰¹çš„ä¿¡æ¯ã€‚`;

console.log("ğŸŒŠ æ™®é€šæµå¼è¾“å‡ºæ¼”ç¤ºï¼ˆæ— ç»“æ„åŒ–ï¼‰\n");

try {
    const stream = await model.stream(prompt);

    let fullContent = '';
    let chunkCount = 0;

    console.log("ğŸ“¡ æ¥æ”¶æµå¼æ•°æ®:\n");

    for await (const chunk of stream) {
        chunkCount++;
        const content = chunk.content;
        fullContent += content;

        process.stdout.write(content); // å®æ—¶æ˜¾ç¤ºæµå¼æ–‡æœ¬
    }

    console.log(`\n\nâœ… å…±æ¥æ”¶ ${chunkCount} ä¸ªæ•°æ®å—\n`);
    console.log(`ğŸ“ å®Œæ•´å†…å®¹é•¿åº¦: ${fullContent.length} å­—ç¬¦`);

} catch (error) {
    console.error("\nâŒ é”™è¯¯:", error.message);
}
